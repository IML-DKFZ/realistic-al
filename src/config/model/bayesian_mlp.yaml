name: bayesian_mlp
weight_decay:  0
learning_rate: 0.001
# weight_decay:  0.001 
load_pretrained: Null
use_ema: False
exclude_bn_bias: True
hidden_dims : [20, 20]
dropout_p: 0
use_bn: True
k: 50
freeze_encoder: False
finetune: False